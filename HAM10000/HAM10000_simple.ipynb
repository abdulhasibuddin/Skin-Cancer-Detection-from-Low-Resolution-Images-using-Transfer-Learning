{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HAM10000_simple.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMg96/cNSNE4MwoOkhZQabf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WfCv32DGjKEu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596311873362,"user_tz":-360,"elapsed":29695,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"5f1a0f5d-7478-4ef8-a025-d5407233c4a6"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aPD7bIA5MQ18","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596311876039,"user_tz":-360,"elapsed":32342,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"52b89751-6210-49f3-9331-5c17b36b3fc0"},"source":["import numpy as np\n","import pandas as pd\n","import random\n","import time\n","import os\n","#os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n","import cv2\n","from tqdm import tqdm\n","\n","import tensorflow as tf\n","from tensorflow.python.keras import Sequential\n","from tensorflow.keras import layers, optimizers\n","from tensorflow.keras.applications import DenseNet121\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.initializers import glorot_uniform\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n","from IPython.display import display\n","from tensorflow.keras import backend as K\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from sklearn.model_selection import train_test_split\n","from keras import optimizers\n","from sklearn.metrics import classification_report, confusion_matrix"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"u4RSwzASMQ4u","colab_type":"code","colab":{}},"source":["readfile_dir = \"drive/My Drive/HAM10000/\"\n","filename = \"HAM10000_metadata.csv\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2-v9PTnBMQ7r","colab_type":"code","colab":{}},"source":["df_metadata = pd.read_csv(readfile_dir+filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5OLz8t6XMQ-f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596311876555,"user_tz":-360,"elapsed":32828,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"3c0a6fd4-ddbe-4481-b56b-ad39bfc9486f"},"source":["list_image_id = list(df_metadata['image_id'].values)\n","print(len(list_image_id))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["10015\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kkNIhBZGMRBk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596311876557,"user_tz":-360,"elapsed":32819,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"61cc816a-bdf5-4579-bce6-853d36d02fc9"},"source":["list_labels = list(df_metadata['dx'].values)\n","print(len(list_labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["10015\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DvGyNHxSO4lo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596311876558,"user_tz":-360,"elapsed":32799,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"c8e0a93a-38b4-4c0b-8ef3-ff843fdbe23b"},"source":["np_unique_classes = np.unique(np.array(list_labels))\n","print(np_unique_classes)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['akiec' 'bcc' 'bkl' 'df' 'mel' 'nv' 'vasc']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dI2IFMPdQfp5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596311876558,"user_tz":-360,"elapsed":32776,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"a9800ebb-7af4-4cc0-ae16-dabb4edb7f74"},"source":["list_label_int = []\n","for img_class in list_labels:\n","    if img_class == 'akiec': #np_unique_classes[0]:\n","        list_label_int.append(0)\n","    elif img_class == 'bcc':\n","        list_label_int.append(1)\n","    elif img_class == 'bkl':\n","        list_label_int.append(2)\n","    elif img_class == 'df':\n","        list_label_int.append(3)\n","    elif img_class == 'mel':\n","        list_label_int.append(4)\n","    elif img_class == 'nv':\n","        list_label_int.append(5)\n","    elif img_class == 'vasc':\n","        list_label_int.append(6)\n","print(len(list_label_int))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["10015\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cHbIt18kSZ1T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596311876559,"user_tz":-360,"elapsed":32748,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"6830cd5f-63ba-4422-bc17-855df4494109"},"source":["np_label_int = np.array(list_label_int)\n","np_label_int.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10015,)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"CUfFzk53Svg_","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4kEX92IQKTq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596312034223,"user_tz":-360,"elapsed":190373,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"978a93d0-e210-4874-85ad-2536053c4b4c"},"source":["df_imageset = pd.read_csv(readfile_dir+'HAM10000_images_all_in_one_Gray_maxPooling_3x3.csv', header=None)\n","df_imageset.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10015, 30000)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"CT62G85H7rFC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"status":"ok","timestamp":1596312034225,"user_tz":-360,"elapsed":190364,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"279bc308-b514-40b4-ff45-78a5bdd22087"},"source":["df_imageset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>29960</th>\n","      <th>29961</th>\n","      <th>29962</th>\n","      <th>29963</th>\n","      <th>29964</th>\n","      <th>29965</th>\n","      <th>29966</th>\n","      <th>29967</th>\n","      <th>29968</th>\n","      <th>29969</th>\n","      <th>29970</th>\n","      <th>29971</th>\n","      <th>29972</th>\n","      <th>29973</th>\n","      <th>29974</th>\n","      <th>29975</th>\n","      <th>29976</th>\n","      <th>29977</th>\n","      <th>29978</th>\n","      <th>29979</th>\n","      <th>29980</th>\n","      <th>29981</th>\n","      <th>29982</th>\n","      <th>29983</th>\n","      <th>29984</th>\n","      <th>29985</th>\n","      <th>29986</th>\n","      <th>29987</th>\n","      <th>29988</th>\n","      <th>29989</th>\n","      <th>29990</th>\n","      <th>29991</th>\n","      <th>29992</th>\n","      <th>29993</th>\n","      <th>29994</th>\n","      <th>29995</th>\n","      <th>29996</th>\n","      <th>29997</th>\n","      <th>29998</th>\n","      <th>29999</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>161</td>\n","      <td>163</td>\n","      <td>165</td>\n","      <td>164</td>\n","      <td>159</td>\n","      <td>160</td>\n","      <td>159</td>\n","      <td>158</td>\n","      <td>160</td>\n","      <td>165</td>\n","      <td>171</td>\n","      <td>169</td>\n","      <td>167</td>\n","      <td>164</td>\n","      <td>170</td>\n","      <td>167</td>\n","      <td>162</td>\n","      <td>163</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>164</td>\n","      <td>166</td>\n","      <td>166</td>\n","      <td>169</td>\n","      <td>170</td>\n","      <td>172</td>\n","      <td>173</td>\n","      <td>173</td>\n","      <td>170</td>\n","      <td>163</td>\n","      <td>163</td>\n","      <td>164</td>\n","      <td>168</td>\n","      <td>168</td>\n","      <td>171</td>\n","      <td>172</td>\n","      <td>172</td>\n","      <td>173</td>\n","      <td>172</td>\n","      <td>170</td>\n","      <td>...</td>\n","      <td>170</td>\n","      <td>164</td>\n","      <td>166</td>\n","      <td>166</td>\n","      <td>162</td>\n","      <td>164</td>\n","      <td>167</td>\n","      <td>168</td>\n","      <td>172</td>\n","      <td>171</td>\n","      <td>166</td>\n","      <td>163</td>\n","      <td>167</td>\n","      <td>168</td>\n","      <td>169</td>\n","      <td>170</td>\n","      <td>172</td>\n","      <td>175</td>\n","      <td>173</td>\n","      <td>173</td>\n","      <td>171</td>\n","      <td>167</td>\n","      <td>166</td>\n","      <td>169</td>\n","      <td>170</td>\n","      <td>173</td>\n","      <td>173</td>\n","      <td>174</td>\n","      <td>176</td>\n","      <td>172</td>\n","      <td>174</td>\n","      <td>173</td>\n","      <td>172</td>\n","      <td>171</td>\n","      <td>170</td>\n","      <td>171</td>\n","      <td>167</td>\n","      <td>162</td>\n","      <td>164</td>\n","      <td>164</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>154</td>\n","      <td>155</td>\n","      <td>154</td>\n","      <td>154</td>\n","      <td>161</td>\n","      <td>161</td>\n","      <td>154</td>\n","      <td>156</td>\n","      <td>154</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>155</td>\n","      <td>152</td>\n","      <td>154</td>\n","      <td>151</td>\n","      <td>154</td>\n","      <td>155</td>\n","      <td>153</td>\n","      <td>157</td>\n","      <td>157</td>\n","      <td>158</td>\n","      <td>154</td>\n","      <td>151</td>\n","      <td>151</td>\n","      <td>155</td>\n","      <td>159</td>\n","      <td>158</td>\n","      <td>155</td>\n","      <td>155</td>\n","      <td>154</td>\n","      <td>163</td>\n","      <td>157</td>\n","      <td>158</td>\n","      <td>155</td>\n","      <td>154</td>\n","      <td>158</td>\n","      <td>162</td>\n","      <td>163</td>\n","      <td>160</td>\n","      <td>...</td>\n","      <td>173</td>\n","      <td>170</td>\n","      <td>170</td>\n","      <td>171</td>\n","      <td>174</td>\n","      <td>170</td>\n","      <td>171</td>\n","      <td>171</td>\n","      <td>163</td>\n","      <td>164</td>\n","      <td>164</td>\n","      <td>165</td>\n","      <td>172</td>\n","      <td>175</td>\n","      <td>175</td>\n","      <td>175</td>\n","      <td>174</td>\n","      <td>173</td>\n","      <td>170</td>\n","      <td>170</td>\n","      <td>169</td>\n","      <td>167</td>\n","      <td>167</td>\n","      <td>166</td>\n","      <td>164</td>\n","      <td>163</td>\n","      <td>164</td>\n","      <td>163</td>\n","      <td>160</td>\n","      <td>159</td>\n","      <td>159</td>\n","      <td>162</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>161</td>\n","      <td>162</td>\n","      <td>156</td>\n","      <td>158</td>\n","      <td>160</td>\n","      <td>161</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>196</td>\n","      <td>198</td>\n","      <td>196</td>\n","      <td>196</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>197</td>\n","      <td>198</td>\n","      <td>197</td>\n","      <td>196</td>\n","      <td>198</td>\n","      <td>198</td>\n","      <td>200</td>\n","      <td>198</td>\n","      <td>200</td>\n","      <td>200</td>\n","      <td>202</td>\n","      <td>201</td>\n","      <td>201</td>\n","      <td>200</td>\n","      <td>199</td>\n","      <td>203</td>\n","      <td>201</td>\n","      <td>198</td>\n","      <td>200</td>\n","      <td>203</td>\n","      <td>204</td>\n","      <td>204</td>\n","      <td>206</td>\n","      <td>204</td>\n","      <td>205</td>\n","      <td>205</td>\n","      <td>205</td>\n","      <td>206</td>\n","      <td>208</td>\n","      <td>205</td>\n","      <td>203</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>204</td>\n","      <td>...</td>\n","      <td>172</td>\n","      <td>172</td>\n","      <td>171</td>\n","      <td>168</td>\n","      <td>165</td>\n","      <td>162</td>\n","      <td>168</td>\n","      <td>165</td>\n","      <td>167</td>\n","      <td>168</td>\n","      <td>166</td>\n","      <td>168</td>\n","      <td>167</td>\n","      <td>164</td>\n","      <td>163</td>\n","      <td>160</td>\n","      <td>161</td>\n","      <td>162</td>\n","      <td>161</td>\n","      <td>157</td>\n","      <td>157</td>\n","      <td>158</td>\n","      <td>161</td>\n","      <td>162</td>\n","      <td>166</td>\n","      <td>170</td>\n","      <td>170</td>\n","      <td>172</td>\n","      <td>175</td>\n","      <td>174</td>\n","      <td>177</td>\n","      <td>177</td>\n","      <td>178</td>\n","      <td>176</td>\n","      <td>175</td>\n","      <td>174</td>\n","      <td>171</td>\n","      <td>170</td>\n","      <td>170</td>\n","      <td>168</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>153</td>\n","      <td>151</td>\n","      <td>153</td>\n","      <td>149</td>\n","      <td>149</td>\n","      <td>153</td>\n","      <td>147</td>\n","      <td>146</td>\n","      <td>147</td>\n","      <td>146</td>\n","      <td>152</td>\n","      <td>150</td>\n","      <td>152</td>\n","      <td>153</td>\n","      <td>154</td>\n","      <td>156</td>\n","      <td>154</td>\n","      <td>155</td>\n","      <td>154</td>\n","      <td>153</td>\n","      <td>153</td>\n","      <td>157</td>\n","      <td>157</td>\n","      <td>156</td>\n","      <td>159</td>\n","      <td>157</td>\n","      <td>158</td>\n","      <td>157</td>\n","      <td>156</td>\n","      <td>157</td>\n","      <td>155</td>\n","      <td>154</td>\n","      <td>156</td>\n","      <td>153</td>\n","      <td>159</td>\n","      <td>158</td>\n","      <td>157</td>\n","      <td>157</td>\n","      <td>157</td>\n","      <td>153</td>\n","      <td>...</td>\n","      <td>153</td>\n","      <td>155</td>\n","      <td>150</td>\n","      <td>150</td>\n","      <td>152</td>\n","      <td>152</td>\n","      <td>154</td>\n","      <td>155</td>\n","      <td>155</td>\n","      <td>155</td>\n","      <td>151</td>\n","      <td>145</td>\n","      <td>145</td>\n","      <td>148</td>\n","      <td>151</td>\n","      <td>145</td>\n","      <td>147</td>\n","      <td>148</td>\n","      <td>148</td>\n","      <td>146</td>\n","      <td>141</td>\n","      <td>144</td>\n","      <td>146</td>\n","      <td>146</td>\n","      <td>145</td>\n","      <td>147</td>\n","      <td>145</td>\n","      <td>144</td>\n","      <td>145</td>\n","      <td>143</td>\n","      <td>141</td>\n","      <td>143</td>\n","      <td>141</td>\n","      <td>139</td>\n","      <td>141</td>\n","      <td>143</td>\n","      <td>143</td>\n","      <td>144</td>\n","      <td>145</td>\n","      <td>146</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>47</td>\n","      <td>45</td>\n","      <td>46</td>\n","      <td>45</td>\n","      <td>44</td>\n","      <td>45</td>\n","      <td>44</td>\n","      <td>43</td>\n","      <td>41</td>\n","      <td>40</td>\n","      <td>49</td>\n","      <td>76</td>\n","      <td>98</td>\n","      <td>119</td>\n","      <td>131</td>\n","      <td>144</td>\n","      <td>148</td>\n","      <td>154</td>\n","      <td>164</td>\n","      <td>164</td>\n","      <td>168</td>\n","      <td>168</td>\n","      <td>164</td>\n","      <td>157</td>\n","      <td>164</td>\n","      <td>165</td>\n","      <td>170</td>\n","      <td>176</td>\n","      <td>176</td>\n","      <td>169</td>\n","      <td>163</td>\n","      <td>170</td>\n","      <td>168</td>\n","      <td>176</td>\n","      <td>177</td>\n","      <td>178</td>\n","      <td>177</td>\n","      <td>181</td>\n","      <td>183</td>\n","      <td>183</td>\n","      <td>...</td>\n","      <td>170</td>\n","      <td>175</td>\n","      <td>175</td>\n","      <td>167</td>\n","      <td>171</td>\n","      <td>171</td>\n","      <td>159</td>\n","      <td>153</td>\n","      <td>153</td>\n","      <td>152</td>\n","      <td>151</td>\n","      <td>149</td>\n","      <td>145</td>\n","      <td>146</td>\n","      <td>154</td>\n","      <td>163</td>\n","      <td>163</td>\n","      <td>150</td>\n","      <td>147</td>\n","      <td>149</td>\n","      <td>146</td>\n","      <td>142</td>\n","      <td>152</td>\n","      <td>154</td>\n","      <td>157</td>\n","      <td>158</td>\n","      <td>149</td>\n","      <td>147</td>\n","      <td>130</td>\n","      <td>116</td>\n","      <td>95</td>\n","      <td>76</td>\n","      <td>53</td>\n","      <td>46</td>\n","      <td>47</td>\n","      <td>46</td>\n","      <td>47</td>\n","      <td>45</td>\n","      <td>46</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10010</th>\n","      <td>45</td>\n","      <td>48</td>\n","      <td>55</td>\n","      <td>55</td>\n","      <td>58</td>\n","      <td>63</td>\n","      <td>69</td>\n","      <td>70</td>\n","      <td>73</td>\n","      <td>77</td>\n","      <td>80</td>\n","      <td>80</td>\n","      <td>85</td>\n","      <td>89</td>\n","      <td>96</td>\n","      <td>100</td>\n","      <td>101</td>\n","      <td>104</td>\n","      <td>106</td>\n","      <td>104</td>\n","      <td>104</td>\n","      <td>104</td>\n","      <td>109</td>\n","      <td>109</td>\n","      <td>109</td>\n","      <td>113</td>\n","      <td>117</td>\n","      <td>117</td>\n","      <td>117</td>\n","      <td>118</td>\n","      <td>117</td>\n","      <td>117</td>\n","      <td>120</td>\n","      <td>121</td>\n","      <td>120</td>\n","      <td>119</td>\n","      <td>124</td>\n","      <td>128</td>\n","      <td>132</td>\n","      <td>134</td>\n","      <td>...</td>\n","      <td>151</td>\n","      <td>150</td>\n","      <td>151</td>\n","      <td>151</td>\n","      <td>150</td>\n","      <td>145</td>\n","      <td>150</td>\n","      <td>150</td>\n","      <td>149</td>\n","      <td>146</td>\n","      <td>147</td>\n","      <td>146</td>\n","      <td>142</td>\n","      <td>140</td>\n","      <td>136</td>\n","      <td>138</td>\n","      <td>136</td>\n","      <td>137</td>\n","      <td>139</td>\n","      <td>135</td>\n","      <td>134</td>\n","      <td>137</td>\n","      <td>137</td>\n","      <td>134</td>\n","      <td>133</td>\n","      <td>131</td>\n","      <td>128</td>\n","      <td>126</td>\n","      <td>121</td>\n","      <td>118</td>\n","      <td>116</td>\n","      <td>113</td>\n","      <td>109</td>\n","      <td>107</td>\n","      <td>102</td>\n","      <td>98</td>\n","      <td>89</td>\n","      <td>87</td>\n","      <td>78</td>\n","      <td>73</td>\n","    </tr>\n","    <tr>\n","      <th>10011</th>\n","      <td>204</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>206</td>\n","      <td>207</td>\n","      <td>212</td>\n","      <td>212</td>\n","      <td>213</td>\n","      <td>213</td>\n","      <td>214</td>\n","      <td>216</td>\n","      <td>216</td>\n","      <td>217</td>\n","      <td>218</td>\n","      <td>216</td>\n","      <td>215</td>\n","      <td>216</td>\n","      <td>220</td>\n","      <td>223</td>\n","      <td>222</td>\n","      <td>223</td>\n","      <td>222</td>\n","      <td>221</td>\n","      <td>224</td>\n","      <td>223</td>\n","      <td>222</td>\n","      <td>222</td>\n","      <td>224</td>\n","      <td>223</td>\n","      <td>222</td>\n","      <td>224</td>\n","      <td>223</td>\n","      <td>225</td>\n","      <td>224</td>\n","      <td>225</td>\n","      <td>227</td>\n","      <td>227</td>\n","      <td>226</td>\n","      <td>225</td>\n","      <td>226</td>\n","      <td>...</td>\n","      <td>231</td>\n","      <td>230</td>\n","      <td>228</td>\n","      <td>230</td>\n","      <td>228</td>\n","      <td>226</td>\n","      <td>226</td>\n","      <td>228</td>\n","      <td>231</td>\n","      <td>229</td>\n","      <td>224</td>\n","      <td>223</td>\n","      <td>221</td>\n","      <td>221</td>\n","      <td>220</td>\n","      <td>220</td>\n","      <td>220</td>\n","      <td>218</td>\n","      <td>217</td>\n","      <td>218</td>\n","      <td>219</td>\n","      <td>217</td>\n","      <td>219</td>\n","      <td>219</td>\n","      <td>218</td>\n","      <td>216</td>\n","      <td>214</td>\n","      <td>216</td>\n","      <td>218</td>\n","      <td>219</td>\n","      <td>217</td>\n","      <td>216</td>\n","      <td>218</td>\n","      <td>217</td>\n","      <td>218</td>\n","      <td>218</td>\n","      <td>218</td>\n","      <td>214</td>\n","      <td>214</td>\n","      <td>214</td>\n","    </tr>\n","    <tr>\n","      <th>10012</th>\n","      <td>153</td>\n","      <td>153</td>\n","      <td>153</td>\n","      <td>153</td>\n","      <td>153</td>\n","      <td>155</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>154</td>\n","      <td>155</td>\n","      <td>155</td>\n","      <td>158</td>\n","      <td>156</td>\n","      <td>158</td>\n","      <td>156</td>\n","      <td>157</td>\n","      <td>157</td>\n","      <td>158</td>\n","      <td>159</td>\n","      <td>159</td>\n","      <td>159</td>\n","      <td>162</td>\n","      <td>164</td>\n","      <td>165</td>\n","      <td>164</td>\n","      <td>164</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>166</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>167</td>\n","      <td>163</td>\n","      <td>164</td>\n","      <td>165</td>\n","      <td>...</td>\n","      <td>182</td>\n","      <td>183</td>\n","      <td>184</td>\n","      <td>186</td>\n","      <td>185</td>\n","      <td>186</td>\n","      <td>185</td>\n","      <td>182</td>\n","      <td>181</td>\n","      <td>184</td>\n","      <td>180</td>\n","      <td>182</td>\n","      <td>185</td>\n","      <td>185</td>\n","      <td>184</td>\n","      <td>187</td>\n","      <td>186</td>\n","      <td>186</td>\n","      <td>186</td>\n","      <td>186</td>\n","      <td>185</td>\n","      <td>183</td>\n","      <td>183</td>\n","      <td>180</td>\n","      <td>180</td>\n","      <td>179</td>\n","      <td>182</td>\n","      <td>180</td>\n","      <td>181</td>\n","      <td>180</td>\n","      <td>179</td>\n","      <td>174</td>\n","      <td>173</td>\n","      <td>173</td>\n","      <td>172</td>\n","      <td>170</td>\n","      <td>169</td>\n","      <td>168</td>\n","      <td>166</td>\n","      <td>164</td>\n","    </tr>\n","    <tr>\n","      <th>10013</th>\n","      <td>61</td>\n","      <td>66</td>\n","      <td>71</td>\n","      <td>72</td>\n","      <td>76</td>\n","      <td>76</td>\n","      <td>77</td>\n","      <td>79</td>\n","      <td>79</td>\n","      <td>77</td>\n","      <td>82</td>\n","      <td>86</td>\n","      <td>88</td>\n","      <td>90</td>\n","      <td>93</td>\n","      <td>95</td>\n","      <td>97</td>\n","      <td>100</td>\n","      <td>101</td>\n","      <td>99</td>\n","      <td>99</td>\n","      <td>101</td>\n","      <td>98</td>\n","      <td>99</td>\n","      <td>101</td>\n","      <td>105</td>\n","      <td>108</td>\n","      <td>108</td>\n","      <td>108</td>\n","      <td>109</td>\n","      <td>108</td>\n","      <td>109</td>\n","      <td>109</td>\n","      <td>108</td>\n","      <td>110</td>\n","      <td>110</td>\n","      <td>110</td>\n","      <td>111</td>\n","      <td>113</td>\n","      <td>115</td>\n","      <td>...</td>\n","      <td>110</td>\n","      <td>112</td>\n","      <td>111</td>\n","      <td>114</td>\n","      <td>112</td>\n","      <td>114</td>\n","      <td>112</td>\n","      <td>112</td>\n","      <td>112</td>\n","      <td>111</td>\n","      <td>111</td>\n","      <td>110</td>\n","      <td>109</td>\n","      <td>105</td>\n","      <td>104</td>\n","      <td>101</td>\n","      <td>100</td>\n","      <td>98</td>\n","      <td>99</td>\n","      <td>98</td>\n","      <td>98</td>\n","      <td>99</td>\n","      <td>99</td>\n","      <td>96</td>\n","      <td>95</td>\n","      <td>94</td>\n","      <td>94</td>\n","      <td>92</td>\n","      <td>91</td>\n","      <td>90</td>\n","      <td>89</td>\n","      <td>87</td>\n","      <td>87</td>\n","      <td>85</td>\n","      <td>83</td>\n","      <td>81</td>\n","      <td>78</td>\n","      <td>74</td>\n","      <td>73</td>\n","      <td>71</td>\n","    </tr>\n","    <tr>\n","      <th>10014</th>\n","      <td>177</td>\n","      <td>181</td>\n","      <td>188</td>\n","      <td>193</td>\n","      <td>195</td>\n","      <td>195</td>\n","      <td>194</td>\n","      <td>195</td>\n","      <td>196</td>\n","      <td>192</td>\n","      <td>193</td>\n","      <td>194</td>\n","      <td>191</td>\n","      <td>189</td>\n","      <td>192</td>\n","      <td>194</td>\n","      <td>193</td>\n","      <td>196</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>195</td>\n","      <td>192</td>\n","      <td>192</td>\n","      <td>195</td>\n","      <td>204</td>\n","      <td>205</td>\n","      <td>207</td>\n","      <td>203</td>\n","      <td>200</td>\n","      <td>196</td>\n","      <td>197</td>\n","      <td>196</td>\n","      <td>198</td>\n","      <td>200</td>\n","      <td>198</td>\n","      <td>197</td>\n","      <td>198</td>\n","      <td>202</td>\n","      <td>201</td>\n","      <td>201</td>\n","      <td>...</td>\n","      <td>195</td>\n","      <td>196</td>\n","      <td>193</td>\n","      <td>191</td>\n","      <td>191</td>\n","      <td>195</td>\n","      <td>198</td>\n","      <td>197</td>\n","      <td>194</td>\n","      <td>193</td>\n","      <td>195</td>\n","      <td>193</td>\n","      <td>190</td>\n","      <td>191</td>\n","      <td>190</td>\n","      <td>191</td>\n","      <td>181</td>\n","      <td>185</td>\n","      <td>186</td>\n","      <td>182</td>\n","      <td>181</td>\n","      <td>178</td>\n","      <td>176</td>\n","      <td>175</td>\n","      <td>171</td>\n","      <td>178</td>\n","      <td>178</td>\n","      <td>174</td>\n","      <td>179</td>\n","      <td>179</td>\n","      <td>174</td>\n","      <td>172</td>\n","      <td>170</td>\n","      <td>165</td>\n","      <td>158</td>\n","      <td>155</td>\n","      <td>152</td>\n","      <td>145</td>\n","      <td>142</td>\n","      <td>137</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10015 rows × 30000 columns</p>\n","</div>"],"text/plain":["       0      1      2      3      4      ...  29995  29996  29997  29998  29999\n","0        161    163    165    164    159  ...    171    167    162    164    164\n","1        154    155    154    154    161  ...    162    156    158    160    161\n","2        196    198    196    196    199  ...    174    171    170    170    168\n","3        153    151    153    149    149  ...    143    143    144    145    146\n","4         47     45     46     45     44  ...     46     47     45     46     46\n","...      ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n","10010     45     48     55     55     58  ...     98     89     87     78     73\n","10011    204    204    203    206    207  ...    218    218    214    214    214\n","10012    153    153    153    153    153  ...    170    169    168    166    164\n","10013     61     66     71     72     76  ...     81     78     74     73     71\n","10014    177    181    188    193    195  ...    155    152    145    142    137\n","\n","[10015 rows x 30000 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"iKMBA_7p7rAJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596312034226,"user_tz":-360,"elapsed":190355,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"73940202-fe69-4201-aff3-324347c55a61"},"source":["np_imageset = df_imageset.values\n","np_imageset.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10015, 30000)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"msVmBW1Ub3DN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596312034227,"user_tz":-360,"elapsed":190343,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"5e08dd70-2527-4a07-9450-2a9069bb80e0"},"source":["list_imageset_reshaped = []\n","for i in range(np_imageset.shape[0]):\n","    reshape_data = np.reshape(np_imageset[i], (200,-1))\n","    list_imageset_reshaped.append(reshape_data)\n","print(len(list_imageset_reshaped))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["10015\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vn1RMpKDcTFC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596312037755,"user_tz":-360,"elapsed":193849,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"2875a276-ee40-42ea-993e-fa456833f6ec"},"source":["np_imageset_reshaped = np.array(list_imageset_reshaped)\n","np_imageset_reshaped.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10015, 200, 150)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"wNzfAWXAD9fb","colab_type":"code","colab":{}},"source":["np_imageset_norm = np_imageset_reshaped/255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceXeOkN4dEuS","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gBycH8_0D9jW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596312040870,"user_tz":-360,"elapsed":196918,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"1eff5cf8-0a74-4207-d97f-18c26b396198"},"source":["split_index = int((len(np_imageset_norm)*10)/100)\n","print(split_index)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1001\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xUSDnI6G7q98","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596312040871,"user_tz":-360,"elapsed":196900,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"329cab12-88f4-4fe4-eb5c-a44c51445c71"},"source":["test_dataset = np_imageset_norm[0:split_index]\n","val_dataset = np_imageset_norm[len(np_imageset_norm)-split_index:len(np_imageset_norm)]\n","train_dataset = np_imageset_norm[split_index:len(np_imageset_norm)-split_index]\n","\n","print('test_dataset.shape =',test_dataset.shape)\n","print('val_dataset.shape =',val_dataset.shape)\n","print('train_dataset.shape =',train_dataset.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test_dataset.shape = (1001, 200, 150)\n","val_dataset.shape = (1001, 200, 150)\n","train_dataset.shape = (8013, 200, 150)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cnkdxyMqUNa3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596312040872,"user_tz":-360,"elapsed":196878,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"a2be7079-6d42-4e5b-c324-b4ffd39a46ca"},"source":["test_dataset2 = np.expand_dims(test_dataset, axis = 3)\n","val_dataset2 = np.expand_dims(val_dataset, axis = 3)\n","train_dataset2 = np.expand_dims(train_dataset, axis = 3)\n","\n","print('test_dataset2.shape =',test_dataset2.shape)\n","print('val_dataset2.shape =',val_dataset2.shape)\n","print('train_dataset2.shape =',train_dataset2.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test_dataset2.shape = (1001, 200, 150, 1)\n","val_dataset2.shape = (1001, 200, 150, 1)\n","train_dataset2.shape = (8013, 200, 150, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E-5_9XJRX2fg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596312040873,"user_tz":-360,"elapsed":196857,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"576ef765-3d77-4089-8b87-fad4a38888bf"},"source":["test_labelset = np_label_int[0:split_index]\n","val_labelset = np_label_int[len(np_label_int)-split_index:len(np_label_int)]\n","train_labelset = np_label_int[split_index:len(np_label_int)-split_index]\n","\n","print('test_labelset.shape =',test_labelset.shape)\n","print('val_labelset.shape =',val_labelset.shape)\n","print('train_labelset.shape =',train_labelset.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test_labelset.shape = (1001,)\n","val_labelset.shape = (1001,)\n","train_labelset.shape = (8013,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GzYUQr6eXOnQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596312040873,"user_tz":-360,"elapsed":196835,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"e3a95088-2897-45fd-fa6d-96c810bb1e7b"},"source":["test_labelset2 = np.expand_dims(test_labelset, axis = 1)\n","val_labelset2 = np.expand_dims(val_labelset, axis = 1)\n","train_labelset2 = np.expand_dims(train_labelset, axis = 1)\n","\n","print('test_labelset2.shape =',test_labelset2.shape)\n","print('val_labelset2.shape =',val_labelset2.shape)\n","print('train_labelset2.shape =',train_labelset2.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test_labelset2.shape = (1001, 1)\n","val_labelset2.shape = (1001, 1)\n","train_labelset2.shape = (8013, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vScCb6hYjTpi","colab_type":"code","colab":{}},"source":["num_classes = 7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8TKj7y9NPTy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596312040874,"user_tz":-360,"elapsed":196809,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"a8607ecb-56df-481f-d3e0-ae3e410b208e"},"source":["np_test_label_one_hot = tf.keras.utils.to_categorical(test_labelset2, num_classes)\n","np_val_label_one_hot = tf.keras.utils.to_categorical(val_labelset2, num_classes)\n","np_train_label_one_hot = tf.keras.utils.to_categorical(train_labelset2, num_classes)\n","\n","print('np_test_label_one_hot.shape =',np_test_label_one_hot.shape)\n","print('np_val_label_one_hot.shape =',np_val_label_one_hot.shape)\n","print('np_train_label_one_hot.shape =',np_train_label_one_hot.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["np_test_label_one_hot.shape = (1001, 7)\n","np_val_label_one_hot.shape = (1001, 7)\n","np_train_label_one_hot.shape = (8013, 7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EIk7WCPYNPfV","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSFYuFZPNPnu","colab_type":"code","colab":{}},"source":["def res_block(X, filter, stage):\n","    \n","  # CONVOLUTIONAL BLOCK\n","  X_copy = X\n","  f1 , f2, f3 = filter\n","\n","  # Main Path\n","  X = Conv2D(f1, (1,1), strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = MaxPool2D((2,2))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n","\n","  # Short path\n","  X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n","  X_copy = MaxPool2D((2,2))(X_copy)\n","  X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n","\n","  # Add data from main and short paths\n","  X = Add()([X,X_copy])\n","  X = Activation('relu')(X)\n","\n","    \n","    \n","  # IDENTITY BLOCK 1\n","  X_copy = X\n","    \n","  # Main Path\n","  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n","\n","  # Add both paths together (Note that we feed the original input as is hence the name \"identity\")\n","  X = Add()([X,X_copy])\n","  X = Activation('relu')(X)\n","\n","    \n","    \n","  # IDENTITY BLOCK 2\n","  X_copy = X\n","\n","  # Main Path\n","  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n","  X = Activation('relu')(X) \n","\n","  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n","  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n","\n","  # Add both paths together (Note that we feed the original input as is hence the name \"identity\")\n","  X = Add()([X,X_copy])\n","  X = Activation('relu')(X)\n","\n","  return X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8bdKF5LnZfGb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596312040876,"user_tz":-360,"elapsed":196774,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"975a8873-7a9c-4092-860e-d3c56b804b4f"},"source":["train_dataset2.shape[1:]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(200, 150, 1)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"T914j5XbNPtW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596312049212,"user_tz":-360,"elapsed":205098,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"4cabb96b-99be-4bed-88f3-cd96c5418a05"},"source":["input_shape = train_dataset2.shape[1:] #(32,32,1) #np_train_dataset.shape #np.expand_dims(np_train_dataset, axis=1) #\n","\n","# Input tensor shape\n","X_input = Input(input_shape)\n","\n","# Zero-padding\n","X = ZeroPadding2D((1,1))(X_input)\n","#X = Input(input_shape)\n","\n","# Stage #1\n","X = Conv2D(64, (5,5), strides= (1,1), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n","#X = Conv2D(64, np_train_dataset.shape[1:3], strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0), data_format='channels_first')(X)\n","#X = Conv2D(64, np_train_dataset.shape[1:3], strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0), data_format='channels_first')(X)\n","X = BatchNormalization(axis =3, name = 'bn_conv1')(X)\n","X = Activation('relu')(X)\n","#print('ok1')\n","#X = MaxPooling2D((3,3), strides= (1,1))(X)\n","#print('ok2')\n","# Stage #2\n","#X = res_block(X, filter= [64,64,256], stage= 2)\n","\n","# Stage #3\n","X = res_block(X, filter= [128,512,128], stage = 2)\n","\n","#X = res_block(X, filter= [256,1024,256], stage = 3)\n","\n","#X = res_block(X, filter= [512,1024,256], stage = 4)\n","\n","#X = res_block(X, filter= [256,1024,256], stage = 5)\n","\n","#X = res_block(X, filter= [64,64,256], stage= 6)\n","\n","# Average Pooling\n","X = AveragePooling2D((2,2), name = 'Averagea_Pooling')(X)\n","\n","# Final layer\n","X = Flatten()(X)\n","X = Dense(512, activation = 'relu')(X)\n","#X = Dropout(0.2)(X)\n","X = Dense(512, activation = 'relu')(X)\n","#X = Dropout(0.1)(X)\n","#X = Dense(1024, activation = 'relu')(X)\n","#X = Dense(512, activation = 'relu')(X)\n","X = Dense(num_classes, activation = 'softmax')(X)\n","\n","\n","model = Model( inputs= X_input, outputs = X)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 200, 150, 1) 0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d (ZeroPadding2D)  (None, 202, 152, 1)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 198, 148, 64) 1664        zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","bn_conv1 (BatchNormalization)   (None, 198, 148, 64) 256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 198, 148, 64) 0           bn_conv1[0][0]                   \n","__________________________________________________________________________________________________\n","res_2_conv_a (Conv2D)           (None, 198, 148, 128 8320        activation[0][0]                 \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 99, 74, 128)  0           res_2_conv_a[0][0]               \n","__________________________________________________________________________________________________\n","bn_2_conv_a (BatchNormalization (None, 99, 74, 128)  512         max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 99, 74, 128)  0           bn_2_conv_a[0][0]                \n","__________________________________________________________________________________________________\n","res_2_conv_b (Conv2D)           (None, 99, 74, 512)  590336      activation_1[0][0]               \n","__________________________________________________________________________________________________\n","bn_2_conv_b (BatchNormalization (None, 99, 74, 512)  2048        res_2_conv_b[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 99, 74, 512)  0           bn_2_conv_b[0][0]                \n","__________________________________________________________________________________________________\n","res_2_conv_copy (Conv2D)        (None, 198, 148, 128 8320        activation[0][0]                 \n","__________________________________________________________________________________________________\n","res_2_conv_c (Conv2D)           (None, 99, 74, 128)  65664       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 99, 74, 128)  0           res_2_conv_copy[0][0]            \n","__________________________________________________________________________________________________\n","bn_2_conv_c (BatchNormalization (None, 99, 74, 128)  512         res_2_conv_c[0][0]               \n","__________________________________________________________________________________________________\n","bn_2_conv_copy (BatchNormalizat (None, 99, 74, 128)  512         max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 99, 74, 128)  0           bn_2_conv_c[0][0]                \n","                                                                 bn_2_conv_copy[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 99, 74, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","res_2_identity_1_a (Conv2D)     (None, 99, 74, 128)  16512       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","bn_2_identity_1_a (BatchNormali (None, 99, 74, 128)  512         res_2_identity_1_a[0][0]         \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 99, 74, 128)  0           bn_2_identity_1_a[0][0]          \n","__________________________________________________________________________________________________\n","res_2_identity_1_b (Conv2D)     (None, 99, 74, 512)  590336      activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn_2_identity_1_b (BatchNormali (None, 99, 74, 512)  2048        res_2_identity_1_b[0][0]         \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 99, 74, 512)  0           bn_2_identity_1_b[0][0]          \n","__________________________________________________________________________________________________\n","res_2_identity_1_c (Conv2D)     (None, 99, 74, 128)  65664       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn_2_identity_1_c (BatchNormali (None, 99, 74, 128)  512         res_2_identity_1_c[0][0]         \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 99, 74, 128)  0           bn_2_identity_1_c[0][0]          \n","                                                                 activation_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 99, 74, 128)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res_2_identity_2_a (Conv2D)     (None, 99, 74, 128)  16512       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn_2_identity_2_a (BatchNormali (None, 99, 74, 128)  512         res_2_identity_2_a[0][0]         \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 99, 74, 128)  0           bn_2_identity_2_a[0][0]          \n","__________________________________________________________________________________________________\n","res_2_identity_2_b (Conv2D)     (None, 99, 74, 512)  590336      activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn_2_identity_2_b (BatchNormali (None, 99, 74, 512)  2048        res_2_identity_2_b[0][0]         \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 99, 74, 512)  0           bn_2_identity_2_b[0][0]          \n","__________________________________________________________________________________________________\n","res_2_identity_2_c (Conv2D)     (None, 99, 74, 128)  65664       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn_2_identity_2_c (BatchNormali (None, 99, 74, 128)  512         res_2_identity_2_c[0][0]         \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 99, 74, 128)  0           bn_2_identity_2_c[0][0]          \n","                                                                 activation_6[0][0]               \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 99, 74, 128)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","Averagea_Pooling (AveragePoolin (None, 49, 37, 128)  0           activation_9[0][0]               \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 232064)       0           Averagea_Pooling[0][0]           \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 512)          118817280   flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 512)          262656      dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 7)            3591        dense_1[0][0]                    \n","==================================================================================================\n","Total params: 121,112,839\n","Trainable params: 121,107,847\n","Non-trainable params: 4,992\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L7DJ4YnNNP8G","colab_type":"code","colab":{}},"source":["#adam = tf.keras.optimizers.Adam(lr = 0.01) #, beta_1=0.9, beta_2=0.999, amsgrad=False\n","optimizer = tf.keras.optimizers.Adam(lr = 0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False) #, beta_1=0.9, beta_2=0.999, amsgrad=False\n","#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QWIS4hpzNQB_","colab_type":"code","colab":{}},"source":["# save the best model with least validation loss\n","checkpointer_name  = \"weights_HAM10000_simple.hdf5\"\n","checkpointer = ModelCheckpoint(filepath = readfile_dir+checkpointer_name, verbose = 1, save_best_only = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9e50Sor8NP-7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1596316052816,"user_tz":-360,"elapsed":4208667,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"1cedc201-51bb-4f30-dff6-2d6ccbd7682b"},"source":["start_time = time.time()\n","history = model.fit(train_dataset2, np_train_label_one_hot, \n","                    shuffle=True, \n","                    batch_size = 8, \n","                    epochs= 15, \n","                    #steps_per_epoch = 2,\n","                    #validation_split = 0.1, \n","                    validation_data = (val_dataset2,np_val_label_one_hot),\n","                    callbacks=[checkpointer]\n","                    )\n","elapsed_time = time.time() - start_time\n","print(\"\\nTime elapsed: \", elapsed_time)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","1002/1002 [==============================] - ETA: 0s - loss: 1.8586 - categorical_accuracy: 0.7039\n","Epoch 00001: val_loss improved from inf to 4.77790, saving model to drive/My Drive/HAM10000/weights_HAM10000_simple.hdf5\n","1002/1002 [==============================] - 448s 447ms/step - loss: 1.8586 - categorical_accuracy: 0.7039 - val_loss: 4.7779 - val_categorical_accuracy: 0.6693\n","Epoch 2/15\n","1002/1002 [==============================] - ETA: 0s - loss: 0.8738 - categorical_accuracy: 0.7518\n","Epoch 00002: val_loss did not improve from 4.77790\n","1002/1002 [==============================] - 439s 438ms/step - loss: 0.8738 - categorical_accuracy: 0.7518 - val_loss: 5.2602 - val_categorical_accuracy: 0.6693\n","Epoch 3/15\n","1002/1002 [==============================] - ETA: 0s - loss: 0.8409 - categorical_accuracy: 0.7528\n","Epoch 00003: val_loss did not improve from 4.77790\n","1002/1002 [==============================] - 439s 438ms/step - loss: 0.8409 - categorical_accuracy: 0.7528 - val_loss: 5.0069 - val_categorical_accuracy: 0.6683\n","Epoch 4/15\n","1002/1002 [==============================] - ETA: 0s - loss: 0.8055 - categorical_accuracy: 0.7537\n","Epoch 00004: val_loss did not improve from 4.77790\n","1002/1002 [==============================] - 439s 438ms/step - loss: 0.8055 - categorical_accuracy: 0.7537 - val_loss: 7.6314 - val_categorical_accuracy: 0.6104\n","Epoch 5/15\n","1002/1002 [==============================] - ETA: 0s - loss: 0.7411 - categorical_accuracy: 0.7618\n","Epoch 00005: val_loss did not improve from 4.77790\n","1002/1002 [==============================] - 439s 438ms/step - loss: 0.7411 - categorical_accuracy: 0.7618 - val_loss: 8.0753 - val_categorical_accuracy: 0.6494\n","Epoch 6/15\n","1002/1002 [==============================] - ETA: 0s - loss: 0.6528 - categorical_accuracy: 0.7789\n","Epoch 00006: val_loss did not improve from 4.77790\n","1002/1002 [==============================] - 438s 438ms/step - loss: 0.6528 - categorical_accuracy: 0.7789 - val_loss: 7.0175 - val_categorical_accuracy: 0.6414\n","Epoch 7/15\n","1002/1002 [==============================] - ETA: 0s - loss: 0.5135 - categorical_accuracy: 0.8131\n","Epoch 00007: val_loss did not improve from 4.77790\n","1002/1002 [==============================] - 439s 438ms/step - loss: 0.5135 - categorical_accuracy: 0.8131 - val_loss: 8.2683 - val_categorical_accuracy: 0.5365\n","Epoch 8/15\n","1002/1002 [==============================] - ETA: 0s - loss: 0.3689 - categorical_accuracy: 0.8640\n","Epoch 00008: val_loss did not improve from 4.77790\n","1002/1002 [==============================] - 438s 437ms/step - loss: 0.3689 - categorical_accuracy: 0.8640 - val_loss: 10.0247 - val_categorical_accuracy: 0.5295\n","Epoch 9/15\n","1002/1002 [==============================] - ETA: 0s - loss: 0.2455 - categorical_accuracy: 0.9114\n","Epoch 00009: val_loss did not improve from 4.77790\n","1002/1002 [==============================] - 439s 438ms/step - loss: 0.2455 - categorical_accuracy: 0.9114 - val_loss: 14.6510 - val_categorical_accuracy: 0.6454\n","Epoch 10/15\n","  70/1002 [=>............................] - ETA: 6:25 - loss: 0.1028 - categorical_accuracy: 0.9732"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-9af61f3e686a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0;31m#validation_split = 0.1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_dataset2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp_val_label_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                     )\n\u001b[1;32m     11\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"TRtGaNZgNP5N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596316080551,"user_tz":-360,"elapsed":16091,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"387ebdea-e325-431e-dac0-68c40c71d67b"},"source":["result = model.evaluate(test_dataset2, np_test_label_one_hot)\n","print(\"Accuracy : {}, Loss: {}\".format(result[1], result[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["32/32 [==============================] - 14s 424ms/step - loss: 13.3339 - categorical_accuracy: 9.9900e-04\n","Accuracy : 0.0009990009712055326, Loss: 13.333940505981445\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PKd-VwqNNP2Y","colab_type":"code","colab":{}},"source":["model_loaded = load_model(readfile_dir+checkpointer_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hT0kpKlSNPzk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596316138078,"user_tz":-360,"elapsed":73595,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"cee633a4-bc82-45c4-9d56-92c97bace028"},"source":["result2 = model_loaded.evaluate(test_dataset2, np_test_label_one_hot)\n","print(\"Accuracy : {}, Loss: {}\".format(result2[1], result2[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["32/32 [==============================] - 13s 403ms/step - loss: 5.5483 - categorical_accuracy: 9.9900e-04\n","Accuracy : 0.0009990009712055326, Loss: 5.548250675201416\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PrY4SZR3NPxs","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kybokbUtNPrD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1596316164102,"user_tz":-360,"elapsed":99597,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"2f86e8fd-6e0b-42f2-bc07-f38ce6372a94"},"source":["#Confution Matrix and Classification Report\n","Y_pred = model_loaded.predict_generator(test_dataset2, len(test_dataset2))\n","y_pred = np.argmax(Y_pred, axis=1)\n","print('Confusion Matrix')\n","print(confusion_matrix(test_labelset2, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-32-e3a96b42f576>:2: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.predict, which supports generators.\n","Confusion Matrix\n","[[   0 1000]\n"," [   0    1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HO4CnW8R3R5o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1596316265933,"user_tz":-360,"elapsed":1394,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"3cc18bbe-8971-43b5-ca79-48c7fd18e580"},"source":["test_labelset2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[2],\n","       [2],\n","       [2],\n","       ...,\n","       [2],\n","       [2],\n","       [2]])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"SgLID-qmNPll","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1596316164103,"user_tz":-360,"elapsed":99583,"user":{"displayName":"ForOnline InternetUse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMAzZA0UZsjrcX05klvyZp6cS9VKiHlpS3ggl=s64","userId":"07063771605322056910"}},"outputId":"31a2f8bd-c08a-4224-988d-c57130d57a6a"},"source":["# Precision [TP/TP+FP] = The ratio of correctly predicted positive observations to the total predicted positive observations.\n","# Recall (Sensitivity) [TP/TP+FN] = The ratio of correctly predicted positive observations to the all observations in actual class - 'yes'.\n","# F1 score [F1 Score = 2*(Recall * Precision) / (Recall + Precision)] = The weighted average of Precision and Recall.\n","# Support = The number of samples of the true response that lie in that class.\n","print('Classification Report:')\n","#target_names = ['Mono', 'Di'] # not ['Di', 'Mono']\n","print(classification_report(test_labelset2, y_pred)) #, target_names=target_names))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Classification Report:\n","              precision    recall  f1-score   support\n","\n","           2       0.00      0.00      0.00      1000\n","           5       0.00      1.00      0.00         1\n","\n","    accuracy                           0.00      1001\n","   macro avg       0.00      0.50      0.00      1001\n","weighted avg       0.00      0.00      0.00      1001\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5XL4YCHbNPjV","colab_type":"code","colab":{}},"source":["print('Classification Report')\n","target_names = ['akiec' 'bcc' 'bkl' 'df' 'mel' 'nv' 'vasc']\n","print(classification_report(test_labelset2, y_pred, target_names=target_names))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KgKZfa1NPc8","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_SaT3v0NPW-","colab_type":"code","colab":{}},"source":["# Getting the model history keys \n","history.history.keys()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ti0dn_KJ7q4C","colab_type":"code","colab":{}},"source":["# plot the training artifacts\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train_loss','val_loss'], loc = 'upper right')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w3588uqEMRNB","colab_type":"code","colab":{}},"source":["plt.plot(history.history['categorical_accuracy'])\n","plt.plot(history.history['val_categorical_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train_accuracy','val_accuracy'], loc = 'upper right')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jnEfCtsnMRQD","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CdVuIoBoMRS9","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6JneDi5MRWB","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLBDxhcuMRZN","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4HxNCreMRcR","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jBG50InMRfN","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cC2LM2DrMRiJ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0o9IJvtWMRlB","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GxzhTKUMRoG","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ptHh-jjkMRrG","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}